# 项目结构

整个HelaList的实现可以分为

## 项目整体结构

首先大致介绍一遍WebDAV协议，这部分占不了太多内容，只需要简单说一下WebDAV相比一般的HTTP，都多了哪些方法即可

之后，从全局角度解释项目的整体结构

项目整体采用了model -> repository -> service -> op -> handler最后路由到http的分层结构

model层其实就是去定义项目当中涉及到的一些基本的数据结构

repository和service是两层对数据库访问的封装

op负责实现各部分的核心功能

handler则是将核心功能封装后注册到路由，从而可以通过HTTP进行调用。

由于model和repository几乎是每一部分都需要设计的功能，所以在后面的讲解中，不会单独拿这两层进行介绍

在上述分层封装的基础上，根据各部分功能的不同，各部分功能又分别又有自己不同的分层设计

如网盘挂载需要设计网盘对应的驱动，因此需要为网盘设计drivers层，直接与网盘服务器端进行交互

又比如项目内部的文件系统需要在驱动层之上封装对文件的操作功能，需要为文件系统设计fs(fileSystem)层

## 文件系统的建立

相关文件：

* /internal/fs: 文件系统基本功能的调用

* /internal/op/fs.go: 文件系统与网盘直接交互的实现，

为了实现对网盘服务器端文件的操作，HelaList内部需要先设计一套简易的文件系统，并实现基本的文件操作功能，如读写删除等功能。

### 文件路径的处理

在这个过程中，我们很有感悟的一点是关于文件路径的处理。

我们知道文件路径有绝对路径，相对路径

除此之外，格式也有所不同，有root/dir, /root/dir, root\\dir, ../dir等多种情况

而且，当我们从网盘端获取到资源时，获取的其实是一个URL，我们需要从URL中提取出文件对应的路径

所以，我们设计了一套清洗路径的方法，一方面是识别URL中的文件路径，另一方面是统一路径格式。

示例代码：

/internal/op/storage.go:

```go
func GetStorageVirtualFilesByPath(prefix string) []model.Obj {
	files := make([]model.Obj, 0)
	storages := storagesMap.Values()
	sort.Slice(storages, func(i, j int) bool {
		if storages[i].GetStorage().Order == storages[j].GetStorage().Order {
			return storages[i].GetStorage().MountPath < storages[j].GetStorage().MountPath
		}
		return storages[i].GetStorage().Order < storages[j].GetStorage().Order
	})

	prefix = utils.FixAndCleanPath(prefix)
	set := mapset.NewSet[string]()
	for _, v := range storages {
		mountPath := utils.GetActualMountPath(v.GetStorage().MountPath)
		if len(prefix) >= len(mountPath) || !utils.IsSubPath(prefix, mountPath) {
			continue
		}
		name := strings.SplitN(strings.TrimPrefix(mountPath[len(prefix):], "/"), "/", 2)[0]
		if set.Add(name) {
			files = append(files, &model.Object{
				Name:         name,
				Size:         0,
				ModifiedTime: v.GetStorage().ModifiedTime,
				IsFolder:     true,
			})
		}
	}
	return files
}
```

### fs层设计

实际上，正如前面提到的文件路径，fs层都是在和“文件路径”打交道

只是看fs层本身，你会认为这真的是一个文件系统，传入文件路径参数，然后fs层就会对该文件进行读写删等处理，最后返回你需要的文件

可以这么说，如果你传入fs层的，是你本地真实的文件路径，然后你再稍微修改一下fs层返回的文件类型，比如通过windows的api返回windows的文件类型啊，或者是通过linux返回呀

你只需要这样稍微修改一下，fs层，就真的可以作为一个文件管理软件使用

不过，我们做的毕竟是网盘，传入路径其实是虚拟的路径，是网盘端文件的路径，而传出参数呢，也是我们项目内部，去适配网盘文件的数据结构。

fs层实现了Read、Write、Put等方法，实际上之后要讲到的网盘层，无非也就是实现这么几个方法

但他们分属于不同的层级，fs层的任务，是设计一个文件管理软件；而接下来要讲到的网盘层，则是负责通过HTTP，直接与网盘进行真实的文件交互。

## 网盘基本功能的实现

相关文件：

* /drivers: 网盘驱动层，直接与网盘服务器交互

* /internal/driver: 网盘接口层，定义网盘需要实现的方法

* /internal/stream: 文件流，当涉及文件的上传/下载时需要

这一部分主要负责实现网盘的上传、下载、新建文件夹、读写删等操作

即，如何通过http，将webdav传输过来的内容转化为HelaList内部的文件系统

### 驱动层实现

驱动层的实现说简单也简单，说难也难。

简单是因为，驱动层的本质就是建立一套HTTP客户端的连接，你只需要写好Request格式，写好Response格式，那么这个HTTP客户端就算实现了。

而有所不同的是，你需要追加一些WebDAV特有的方法头，比如COPY, MOVE, 甚至WebDAV还支持对文件的上锁LOCK。你需要额外为这些方法做处理

另外就是访问其他网盘需要的用户名和密码，这些不必多说

### 网盘接口层实现

有人会问，欸你不是只实现了一个网盘功能吗，做接口干嘛？

这个就纯粹是个人认为的代码规范问题了。

在网盘的接口层，我们定义了一个网盘需要具备的所有操作，需要附带的所有信息，包括用户名密码之类

而驱动层的任务就是把接口层声明的这些函数实现而已

一方面从规范角度来讲，这样写其实规避了“硬编码”问题

后端并不是直接与webdav网盘交互，而是与网盘接口进行交互。

换句话说，尽管受限于时间，我们在一个月时间里只实现了一个简单的webdav网盘，但是，微软的onedrive也好，谷歌的google drive也好，他们都是有对外开放的api的

如果我们心血来潮，突然想给HelaList再做一种网盘适配，那么凭借网盘接口层的存在，这个功能的实现会非常省事。

**本质还是一个问题，避免硬编码**

就像我最近了解到一些游戏开发的知识，说游戏的那种按键设置功能，还有语言包功能，他们都是怎么实现的呢？答案就是类似于实现了一种接口，然后根据设置参数的不同，调用不同的具体实现。

### 文件流实现

本项目的文件流围绕一个名为File的接口展开:

```go
type File interface {
    io.Reader
    io.ReaderAt
    io.Seeker
}
```

该接口包含的三个方法，啊其实也是接口因为go允许接口套接口。

总之这三个方法均来自go原生的文件流支持。Reader允许对文件流进行顺序访问

ReaderAt和Seeker用于实现文件流的随机访问，因为对文件的操作是并发进行的，我们可以通过偏移量，将不同协程定位在文件的不同位置，然后并发下载

这个过程中还伴随着文件缓存，当然这就不多介绍了。

文件流更重要的功能，是他成为了文件上传/下载以及多媒体在线预览的一个基石。

## AI Agent相关功能的实现

相关文件：

* /ai: MCP功能的实现

* /internal/rag: RAG功能的实现

* /internal/repository/chat.go: LLM与数据库交互的实现，是RAG功能的关键

* /internal/service/chat.go: 提示词的调优，以及ai操作的实现(如让ai查找图片)

实际上，即使没有这一部分，HelaList作为一个网盘，也绝对够用了

但是我们成立这个项目之初，其实就是为了解决网盘产品中没有AI的痛点问题，所以AI Agent部分的实现，反而是HelaList最重要的部分

同时，也正是因为AI Agent在定位上就与其他功能的耦合度不高，因此在进行功能开发时，AI Agent部分的开发。是可以和网盘基本功能并行进行的。

在AI Agent部分，我们主要实现了两个功能：函数调用和RAG。

### 函数调用

如何让大语言模型学会使用函数呢？

这个问题，有两种不同的答案，一个较为简易，更倾向于提示词工程方面的优化；另一个则有些繁琐，但格式规范，是目前OpenAI、Anthropic等公司的SDK也在采用的方式

#### 方法一 正则表达式匹配

我们让大模型调用函数，其实本质上是希望，在我们向大模型发送输入，等待大模型输出的这一段过程之间，某个函数被执行，得到一个返回值，然后大模型将这个返回值加入到自己的输出当中

也即，我们需要知道，大模型需要发送什么，才能让函数，从大模型的语句中，检测到需要的操作呢？

答案是，正则匹配。

我们事先在大模型的系统提示词当中规定了，模型在检测到用户有调用函数的需求时，会在输出中包含一段固定格式的内容，[OPERATION]

只要通过正则匹配，检测到了提示词当中的[OPERATION]，那么后端现在就知道，大模型在调用函数了，并执行相应的函数，返回值给大模型的输出。

#### 方法二 结构化格式

正则匹配固然简单，但是所有函数操作的检测，都只是依靠你人为规定的一个关键字进行匹配，显然非常脆弱，很容易出现错误触发的情况

于是，既然是格式的问题，那我们就规范格式

同样是在系统提示词中预先要求大模型以某种格式进行函数调用。不过这一次，采用的是JSON的结构化格式来调用函数，包括函数的签名，函数的传入参数等信息。

这样一来，不仅格式得到了规范化，函数调用更加稳健。

而且，规范的传入和传出格式，也方便了开发者专门为AI设计函数工具。

我不知道在坐同学有没有玩过MCP或者类似的Agent工具的，现在OpenAI也好Anthropic也好，他们开发的工具SDK都有一种功能。**当你要将某个函数作为提供给AI的工具使用时，你只需要写上一段自然语言描述的Description，以及传入你想让AI执行的函数。好了，AI已经学会怎么用这个函数了。**

**这个过程，也叫做Function calling**

#### 其实还有个方法三

函数调用，其实还有一个方法三，那就是目前正流行的MCP协议。

简单来说，MCP协议是彻彻底底将函数的注册，输出，客户端的规范和服务端的规范全都进行了统一，几乎是实现了AI Agent领域的“统一度量衡”

现在，不管是微软的Copilot也好，还是谷歌的GeminiCLI，Claude的Claude Code。只需要在配置文件中写入一段调用参数，这个AI就能学会自己刷微博，自己搜地图。

但怎么说呢，我们的项目实现了正则表达式匹配和Function calling两种方法，唯独没有继续尝试MCP

这并不是说MCP就存在什么缺点，相反，MCP是这三种方法中使用体验最好的。

只是，如果要打个比方的话，Function calling方法，是让大语言模型学会使用函数。而MCP协议，则是让AI学会使用一个软件。

一点比较有生活的个人体验，我自己下载安装了GeminiCLI，并且安装了高德地图的MCP插件。安装的过程非常简单，我只需要把高德地图官网的配置复制粘贴到我Gemini的配置文件就行了。

然后呢，我试着让Gemini告诉我，从九龙湖校区到南京南站的最快路径是什么。Gemini马上就告诉我了，而且和我平时走的路线完全一致。

更重要的是，这个过程一定不会出现幻觉，因为Gemini只是把高德地图API的返回结果复述了一遍而已。

一点个人感慨，AI真的是越来越强大了，MCP也是现在各软件厂商在适配的焦点。

### RAG功能实现

来到第二个功能，RAG的实现。

因为这里的人工智能的同学也不少，整体上对RAG原理方面肯定非常熟悉，所以我就只简单介绍一下RAG的原理，快速带过。

RAG的出现，目的是为了让AI能够记住对话的上下文。因为你实际调用api进行ai对话的话就会发现，ai说一句是一句，完全没有记忆。

那么，在RAG之前，人们是如何让AI学会记忆的呢

方法很朴素，就是把AI的历史记录都存放在数据库里，每次要对话之前，AI先从数据库过一遍，资金最近都说过什么话

可朴素的代价就是，AI是有输入token限制的，一旦超出一定字数，那么AI就无法正常运行了

因此，我们不需要让AI把所有历史对话都记住，只需要记住关键点就可以了

怎么找关键点呢？这就是RAG的作用。

简单来说，RAG的原理就是，将每一个输入输出的长段落，切分成多个小块，并将这些小块转化为一个多维向量，写在计算机里就是一个多维数组

这些向量会被存储在数据库中

当我们向AI发送一段输入token时，这一段输入也会被拆分，被向量化

然后，我们根据一定的方式，从数据库中寻找与我们的输入向量相似的向量，方法可能是余弦相似度，也可能是求点积，等等等等。

那么，找出来的和我们相似的向量，其实就是AI需要记住的关键记忆。于是，AI从数据库中读取这些记忆，由此实现了AI的上下文能力。

我们采用了Qdrant作为向量数据库——实际上，不管是MySQL，还是PostgreSQL，在新版本当中，都是具备向量数据库的功能的

但是，他们的内核毕竟还是对象型数据库，而向量数据库需要的是大量的运算，和我们常说的什么B+树结构索引结构，其实相性并不是很好。属于是强行兼容了。

而Qdrant的定位就是专业的向量数据库，并且Qdrant免费开源，教程也非常通俗易懂。所以我们选了Qdrant

RAG功能演示（下面附图）